
# Information Retrieval


---

### **1. Term-Document Index**
A **term-document index** organizes terms (words) and their occurrences across documents.

#### **Example Table:**

| Term       | Document 1 | Document 2 | Document 3 | Document 4 |
|------------|------------|------------|------------|------------|
| Data       | 1          | 0          | 1          | 0          |
| Retrieval  | 0          | 1          | 1          | 1          |
| Query      | 1          | 1          | 0          | 1          |
| System     | 0          | 0          | 1          | 1          |

- **Rows:** Terms (keywords in the documents).
- **Columns:** Documents (e.g., Document 1, Document 2).
- **Cell Values:** Binary (1 for presence, 0 for absence) or frequency (number of occurrences).

#### **Visualization:**
```plaintext
Data       →  [1, 0, 1, 0]
Retrieval  →  [0, 1, 1, 1]
Query      →  [1, 1, 0, 1]
System     →  [0, 0, 1, 1]
```

---

### **2. Incidence Vector**
The **incidence vector** is derived from the term-document index and represents a term's presence in binary form.

#### **Example:**
- For the term "Query," the incidence vector is `[1, 1, 0, 1]`.

---

### **3. Boolean Query Processing**
#### **Query Example**:  
"Retrieve documents containing 'Data' AND 'Query' but NOT 'System.'"

#### **Steps:**
1. **Incidence Vectors**:
   - "Data" → `[1, 0, 1, 0]`
   - "Query" → `[1, 1, 0, 1]`
   - "System" → `[0, 0, 1, 1]`

2. **Apply Boolean Operations**:
   - **AND (Data ∩ Query):** `[1, 0, 1, 0]` AND `[1, 1, 0, 1]` → `[1, 0, 0, 0]`
   - **NOT (¬System):** NOT `[0, 0, 1, 1]` → `[1, 1, 0, 0]`
   - Combine results: `[1, 0, 0, 0]` AND `[1, 1, 0, 0]` → `[1, 0, 0, 0]`

#### **Result**:
- **Document 1** satisfies the query.

---

### **4. Graph-Based Visualization**
#### **Vertices and Edges:**
- Represent terms and documents as vertices.
- Edges indicate which documents contain specific terms.

#### **Graph:**
```
     (Data)       (Query)
       | \         / |
       |  (D1)   (D2) |
       |     \   /    |
    (Retrieval)---(System)
          |         |
         (D3)     (D4)
```

- **D1, D2, D3, D4**: Documents.
- **Edges**: Relationships between terms and documents.


https://github.com/user-attachments/assets/0766688c-6f4d-4015-9e3c-9d176617c930


---

### **5. Vector Space Model (Ranking Query Results)**
Instead of binary presence, rank documents by relevance using **Term Frequency-Inverse Document Frequency (TF-IDF)**.

#### **Example Calculation:**
- Term Frequency (TF) of "Query" in Document 1 = 1.
- Document Frequency (DF) of "Query" = 3 (appears in 3 documents).
- TF-IDF = TF × log(Total Documents / DF) = $\(1 \times \log(4/3)\)$.

Rank documents based on their TF-IDF scores.

#### **3D Visualization of Relevance**:
- **Axes**: Terms (X), Documents (Y), Relevance Scores (Z).
- Height represents relevance.

---

### **Posting List**:
- A list of document IDs where a term occurs.  
  Example:  
  - Term: "cat"  
  - Posting List: [7, 3, 10, 42]



https://github.com/user-attachments/assets/408ecc13-c59f-4a1a-9953-375fc5fbbf47





---

## **Westlaw (Boolean Retrieval Program)**


https://github.com/user-attachments/assets/0c008c90-1ef6-41f5-8f35-e14330445399


### **The Boolean Retrieval Model**
1. **Query Optimization**:  
   Rearrange queries to minimize processing time.  
   Example:  
   - Query: $(A \text{ AND } B) \text{ OR } C$  
   - Optimize: Evaluate the smaller term first (e.g., $A \text{ AND } B$).

2. **Query Processing**:  
   Use boolean operators (AND, OR, NOT) to retrieve documents.  
   Example:  
   - Query: "cat AND dog"  
   - Result: Documents containing both "cat" and "dog".




https://github.com/user-attachments/assets/74c8e5a8-4c85-4bf1-99a6-5695492c1193



### **Phrase Query**:  
Search for exact phrases.  
Example:  
- Query: `"cat sleeps"`  
- Result: Documents where "cat sleeps" appears as a phrase.

### **Biword Index**:  
Stores consecutive word pairs to handle phrase queries.  
Example:  
- Sentence: "The cat sleeps."  
- Biword Index: [("The cat"), ("cat sleeps")].

---

### **Proximity Queries**:
- Search for terms appearing within a certain distance.  
  Uses **Positional Index**:  
  Each term is stored with positions in documents.  
  Example:  
  - Term: "cat"  
  - Positional Index: [Doc1: (2, 10), Doc2: (5)].

#### **Positional Index**:  
- Larger but more useful and now standard.  
  Example:  
  - Query: `"cat sleeps" within 5 words`  
  - Match: Documents where "cat" and "sleeps" are within 5-word positions.

#### **Non-Positional Index**:  
- Does not store positions.  
  Example:  
  - Query: "cat"  
  - Match: Returns all documents with "cat" without location details.



https://github.com/user-attachments/assets/9ef2e0b1-d271-4a01-8eb3-2ec6694d95ee



---

## **Scoring and Weighting Schemes**

### **Term Frequency-Inverse Document Frequency (TF-IDF)**:
1. **Term Frequency (TF)**:  
   Counts the number of times a term appears in a document.  
   Formula:  
   $TF(t) = \frac{\text{Count of term } t \text{ in document}}{\text{Total terms in document}}$

2. **Inverse Document Frequency (IDF)**:  
   Reduces the weight of common terms.  
   Formula:  
   $IDF(t) = \log \left( \frac{\text{Total documents}}{\text{Number of documents containing } t} \right)$

3. **TF-IDF**:  
   Combines TF and IDF.  
   Formula:  
   $TF-IDF(t) = TF(t) \times IDF(t)$

---

# Ranked Retrieval Model

## **Feast and Famine Problem**
The **feast and famine problem** refers to the issue of having either too many or too few relevant documents for a query. It can occur when a retrieval model overly favors certain terms, leading to either an overload of results (feast) or a lack of results (famine).

### **Free Text Queries**
- Queries in natural language, allowing flexibility in input.
- May lead to more diverse results but also less precision due to ambiguity.

### **Jaccard Coefficient** (Issues)
The Jaccard coefficient is used to measure similarity between two sets.  
Formula:  
$\text{Jaccard}(A, B) = \frac{|A \cap B|}{|A \cup B|}$  

**Issues**:  
- Sensitive to set size.
- Can overestimate similarity when the sets are large.

### **Term-Document Count Matrix** - Bag of Words
- A matrix where rows represent documents, and columns represent terms (words).
- Values represent term frequency (how many times a term appears in a document).

### **Term-Frequency Weighting**
- Weighs terms based on their frequency in a document.
- Common term frequency weighting:  
  $TF(t, D) = \frac{\text{Number of occurrences of term t in document D}}{\text{Total terms in D}}$

### **IDF - Inverse Document Frequency Weighting**
- Measures how rare a term is across a collection of documents.  
  Formula:  
  $IDF(t) = \log \left( \frac{N}{df(t)} \right)$  
  where $N$ is the total number of documents and $df(t)$ is the number of documents containing the term $t$.

### **Collection Frequency vs. Social Frequency**
- **Collection Frequency**: The number of times a term appears across the entire document collection.
- **Social Frequency**: Refers to how frequently a term is used within a social context or specific subgroup.

---

# Vector Space Models

## **Query as a Vector**
- In vector space models, both queries and documents are represented as vectors in a multi-dimensional space where each dimension corresponds to a term in the collection.
![image](https://github.com/user-attachments/assets/97fc8a57-1e45-4425-870b-f7f5bd0b15eb)

## **Why Not Euclidean Distance?**
- **Euclidean distance** is not ideal for text data because it does not handle differences in length and magnitude well.
- **Cosine Similarity** is used instead, as it measures the cosine of the angle between two vectors, making it more suited for text comparison.

### **Cosine Similarity**:  
Formula:  
$\text{cosine similarity}(A, B) = \frac{A \cdot B}{\|A\| \|B\|}$  
Where $A$ and $B$ are vectors representing two documents or a query and a document.

---

# Length Normalization

### **Length Normalization**:  
- **L2 Norm** (Euclidean norm) is used to normalize vectors, ensuring that all vectors have a magnitude of 1. This allows for comparisons based on direction rather than magnitude.
- Normalizing vectors makes the vectors have a **unit length**, which simplifies similarity calculations.  

Formula for **L2 Normalization**:  

<img width="459" alt="image" src="https://github.com/user-attachments/assets/86e59295-fe94-48d6-8f81-8f5754ddd540" />



Where $A_i$ is the $i$-th component of the vector.

### **Length Normalizing** = Making Unit Vectors  
Unit vectors ensure that the angle between them can be used for similarity comparisons, removing the influence of the vector's magnitude.

---

## **Calculating TF-IDF Cosine Scores**
- This involves computing the term frequency-inverse document frequency (TF-IDF) for each term and then calculating the cosine similarity between the query and documents using the TF-IDF values.

---

# Evaluating Search Engines

## **Evaluating Search Engines**
1. **Precision** and **Recall** (as discussed earlier) are crucial for evaluating the performance of search engines.
2. **F-measure** combines both precision and recall into one metric:  
  $F_1 = 2 \cdot \frac{\text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}}$

---

# Named Entity Recognition (NER)

## **Morphemes**
- A **morpheme** is the smallest meaningful unit in a language that cannot be further divided.  
  Example: "incoming" consists of two morphemes: "in-" and "coming".

## **Why is NER Hard?**
- **Segmentation**: Correctly splitting text into entities.
- **Type Ambiguity**: Words can belong to multiple categories, making it challenging to classify them correctly.
![image](https://github.com/user-attachments/assets/bcbd7972-ef0e-4b7c-90cc-a18bc9d7aa54)

### **BIO-Tagging** / **IO-Tagging** / **BIOES-Tagging**:
- **BIO-tagging**: Classifies tokens as **Beginning**, **Inside**, or **Outside** an entity.  
  Example:  
  - "Steve" (B-PER)  
  - "Jobs" (I-PER)  
  - "is" (O)  

- **IO-tagging**: Similar to BIO, but lacks the "Beginning" tag, using only **Inside** and **Outside** labels.

- **BIOES-tagging**: Includes **End** and **Single** tags for more precise entity boundaries.  
  Example:  
  - "Steve" (B-PER)  
  - "Jobs" (E-PER)  
  - "is" (O)


![image](https://github.com/user-attachments/assets/7a09df74-795b-4c3d-89de-80fe8386a6d1)

---

## **Open vs. Closed Words in POS Tagging**

- **Open Words**: Words that can take on new meanings or forms in different contexts (e.g., nouns, verbs, adjectives).
- **Closed Words**: Words that are limited to a specific function (e.g., prepositions, conjunctions, articles).




## Summary Table

| **Aspect**               | **Description**                                                   | **Example**                                              |
|--------------------------|-------------------------------------------------------------------|----------------------------------------------------------|
| **Posting List**          | List of document IDs where a term occurs.                       | Term: "cat", Posting List: [7, 3, 10, 42].               |
| **Phrase Query**          | Searches for exact phrases in documents.                       | Query: `"cat sleeps"`.                                   |
| **Proximity Queries**     | Finds terms within a certain distance.                         | Query: `"cat sleeps" within 5 words.`                    |
| **TF-IDF**                | Scoring scheme based on term frequency and rarity.             | $TF-IDF(t) = TF(t) \times IDF(t)$.                      |
