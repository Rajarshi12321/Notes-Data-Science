# Naive Bayes

### **Assumptions**
1. **Bag of Words Assumption**:  
   Treats each word in the text as an independent feature, ignoring its position.  
   Example: "The cat sleeps" and "Sleeps the cat" are treated the same.

2. **Conditional Independence Assumption**:  
   Assumes that the presence of a word in a document is independent of the presence of other words, given the class.  
   Formula:  
   $P(c|x) \propto P(c) \prod_{i=1}^n P(x_i|c)$  
   where $c$ is the class and $x_i$ is the feature.

### **Why Use Log Probabilities Instead of Probabilities?**
- **Avoid underflow**: Multiplying many small probabilities can result in numerical instability.
- **Simpler computations**: Logarithms turn products into sums.  
  Formula:  
  $\log P(c|x) = \log P(c) + \sum_{i=1}^n \log P(x_i|c)$

---

# Precision and Recall

### **Definitions**
1. **Precision**:  
   Measures how many predicted positive instances are correct.  
   Formula:  
   $\text{Precision} = \frac{\text{True Positives (TP)}}{\text{True Positives (TP)} + \text{False Positives (FP)}}$  
   **Important** when **false positives** are costly.  
   Example: Spam detection (prevent mislabeling important emails as spam).

2. **Recall**:  
   Measures how many actual positive instances are correctly predicted.  
   Formula:  
   $\text{Recall} = \frac{\text{True Positives (TP)}}{\text{True Positives (TP)} + \text{False Negatives (FN)}}$  
   **Important** when **false negatives** are costly.  
   Example: Disease detection (missing a positive case is dangerous).

---

# Information Retrieval

### **Posting List**:
- A list of document IDs where a term occurs.  
  Example:  
  - Term: "cat"  
  - Posting List: [7, 3, 10, 42]

---

## **Westlaw (Boolean Retrieval Program)**

### **The Boolean Retrieval Model**
1. **Query Optimization**:  
   Rearrange queries to minimize processing time.  
   Example:  
   - Query: $(A \text{ AND } B) \text{ OR } C$  
   - Optimize: Evaluate the smaller term first (e.g., $A \text{ AND } B$).

2. **Query Processing**:  
   Use boolean operators (AND, OR, NOT) to retrieve documents.  
   Example:  
   - Query: "cat AND dog"  
   - Result: Documents containing both "cat" and "dog".

### **Phrase Query**:  
Search for exact phrases.  
Example:  
- Query: `"cat sleeps"`  
- Result: Documents where "cat sleeps" appears as a phrase.

### **Biword Index**:  
Stores consecutive word pairs to handle phrase queries.  
Example:  
- Sentence: "The cat sleeps."  
- Biword Index: [("The cat"), ("cat sleeps")].

---

### **Proximity Queries**:
- Search for terms appearing within a certain distance.  
  Uses **Positional Index**:  
  Each term is stored with positions in documents.  
  Example:  
  - Term: "cat"  
  - Positional Index: [Doc1: (2, 10), Doc2: (5)].

#### **Positional Index**:  
- Larger but more useful and now standard.  
  Example:  
  - Query: `"cat sleeps" within 5 words`  
  - Match: Documents where "cat" and "sleeps" are within 5-word positions.

#### **Non-Positional Index**:  
- Does not store positions.  
  Example:  
  - Query: "cat"  
  - Match: Returns all documents with "cat" without location details.

---

## **Scoring and Weighting Schemes**

### **Term Frequency-Inverse Document Frequency (TF-IDF)**:
1. **Term Frequency (TF)**:  
   Counts the number of times a term appears in a document.  
   Formula:  
   $TF(t) = \frac{\text{Count of term } t \text{ in document}}{\text{Total terms in document}}$

2. **Inverse Document Frequency (IDF)**:  
   Reduces the weight of common terms.  
   Formula:  
   $IDF(t) = \log \left( \frac{\text{Total documents}}{\text{Number of documents containing } t} \right)$

3. **TF-IDF**:  
   Combines TF and IDF.  
   Formula:  
   $TF-IDF(t) = TF(t) \times IDF(t)$

---

## Summary Table

| **Aspect**               | **Description**                                                   | **Example**                                              |
|--------------------------|-------------------------------------------------------------------|----------------------------------------------------------|
| **Bag of Words Assumption** | Treats word positions as irrelevant.                            | "The cat sleeps" = "Sleeps the cat."                     |
| **Conditional Independence** | Assumes features are independent given the class.              | $P(c\|x) \propto P(c) \prod P(x_i\|c)$.                    |
| **Precision**             | Measures accuracy of positive predictions.                      | Spam detection.                                          |
| **Recall**                | Measures completeness of positive predictions.                  | Disease detection.                                       |
| **Posting List**          | List of document IDs where a term occurs.                       | Term: "cat", Posting List: [7, 3, 10, 42].               |
| **Phrase Query**          | Searches for exact phrases in documents.                       | Query: `"cat sleeps"`.                                   |
| **Proximity Queries**     | Finds terms within a certain distance.                         | Query: `"cat sleeps" within 5 words.`                    |
| **TF-IDF**                | Scoring scheme based on term frequency and rarity.             | $TF-IDF(t) = TF(t) \times IDF(t)$.                      |
