# Naive Bayes

### **Assumptions**
1. **Bag of Words Assumption**:  
   Treats each word in the text as an independent feature, ignoring its position.  
   Example: "The cat sleeps" and "Sleeps the cat" are treated the same.

2. **Conditional Independence Assumption**:  
   Assumes that the presence of a word in a document is independent of the presence of other words, given the class.  
   Formula:  
   $P(c|x) \propto P(c) \prod_{i=1}^n P(x_i|c)$  
   where $c$ is the class and $x_i$ is the feature.

### **Why Use Log Probabilities Instead of Probabilities?**
- **Avoid underflow**: Multiplying many small probabilities can result in numerical instability.
- **Simpler computations**: Logarithms turn products into sums.  
  Formula:  
  $\log P(c|x) = \log P(c) + \sum_{i=1}^n \log P(x_i|c)$



https://github.com/user-attachments/assets/69c260e0-7b29-4eb6-af36-eca921bfd597



---

# Precision and Recall

### **Definitions**
1. **Precision**:  
   Measures how many predicted positive instances are correct.  
   Formula:  
   $\text{Precision} = \frac{\text{True Positives (TP)}}{\text{True Positives (TP)} + \text{False Positives (FP)}}$  
   **Important** when **false positives** are costly.  
   Example: Spam detection (prevent mislabeling important emails as spam).

2. **Recall**:  
   Measures how many actual positive instances are correctly predicted.  
   Formula:  
   $\text{Recall} = \frac{\text{True Positives (TP)}}{\text{True Positives (TP)} + \text{False Negatives (FN)}}$  
   **Important** when **false negatives** are costly.  
   Example: Disease detection (missing a positive case is dangerous).

### Easy Example to Remember Precision, Recall, and the Confusion Matrix

#### **Scenario**: Detecting Spam Emails  
You are building a system to classify emails as **Spam** or **Not Spam**.

---

### **Confusion Matrix**
|                  | Predicted Spam | Predicted Not Spam |
|------------------|----------------|---------------------|
| **Actual Spam**   | True Positive (TP) = 40 | False Negative (FN) = 10 |
| **Actual Not Spam** | False Positive (FP) = 5  | True Negative (TN) = 45  |

---

### **Definitions**
1. **Precision**: Of all emails predicted as Spam, how many are actually Spam?  
   $\text{Precision} = \frac{TP}{TP + FP} = \frac{40}{40 + 5} = 0.89   $

3. **Recall (Sensitivity)**: Of all actual Spam emails, how many were correctly predicted?  
   $\text{Recall} = \frac{TP}{TP + FN} = \frac{40}{40 + 10} = 0.8 $

4. **Accuracy**: How many emails were classified correctly overall?  

   $\text{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN} = \frac{40 + 45}{40 + 45 + 5 + 10} = 0.85 $
   
![image](https://github.com/user-attachments/assets/40e626ad-3667-46d4-a77a-5181ba0814f4)

---

### **Easy Way to Remember**  
- **Precision = Relevant out of Retrieved** (How *precise* is your Spam detector in identifying Spam?)  
- **Recall = Retrieved out of Relevant** (How much Spam did your system *recall* from the total actual Spam?)  

---

### Real-World Analogy  
```
Think of a **precision-focused system** like a detective who ensures every suspect caught is truly guilty (fewer FP).  
Think of a **recall-focused system** like a wide net to catch all criminals, even if it catches some innocent people (fewer FN).
```
---

# Information Retrieval

### **Posting List**:
- A list of document IDs where a term occurs.  
  Example:  
  - Term: "cat"  
  - Posting List: [7, 3, 10, 42]

---

## **Westlaw (Boolean Retrieval Program)**

### **The Boolean Retrieval Model**
1. **Query Optimization**:  
   Rearrange queries to minimize processing time.  
   Example:  
   - Query: $(A \text{ AND } B) \text{ OR } C$  
   - Optimize: Evaluate the smaller term first (e.g., $A \text{ AND } B$).

2. **Query Processing**:  
   Use boolean operators (AND, OR, NOT) to retrieve documents.  
   Example:  
   - Query: "cat AND dog"  
   - Result: Documents containing both "cat" and "dog".

### **Phrase Query**:  
Search for exact phrases.  
Example:  
- Query: `"cat sleeps"`  
- Result: Documents where "cat sleeps" appears as a phrase.

### **Biword Index**:  
Stores consecutive word pairs to handle phrase queries.  
Example:  
- Sentence: "The cat sleeps."  
- Biword Index: [("The cat"), ("cat sleeps")].

---

### **Proximity Queries**:
- Search for terms appearing within a certain distance.  
  Uses **Positional Index**:  
  Each term is stored with positions in documents.  
  Example:  
  - Term: "cat"  
  - Positional Index: [Doc1: (2, 10), Doc2: (5)].

#### **Positional Index**:  
- Larger but more useful and now standard.  
  Example:  
  - Query: `"cat sleeps" within 5 words`  
  - Match: Documents where "cat" and "sleeps" are within 5-word positions.

#### **Non-Positional Index**:  
- Does not store positions.  
  Example:  
  - Query: "cat"  
  - Match: Returns all documents with "cat" without location details.

---

## **Scoring and Weighting Schemes**

### **Term Frequency-Inverse Document Frequency (TF-IDF)**:
1. **Term Frequency (TF)**:  
   Counts the number of times a term appears in a document.  
   Formula:  
   $TF(t) = \frac{\text{Count of term } t \text{ in document}}{\text{Total terms in document}}$

2. **Inverse Document Frequency (IDF)**:  
   Reduces the weight of common terms.  
   Formula:  
   $IDF(t) = \log \left( \frac{\text{Total documents}}{\text{Number of documents containing } t} \right)$

3. **TF-IDF**:  
   Combines TF and IDF.  
   Formula:  
   $TF-IDF(t) = TF(t) \times IDF(t)$

---

## Summary Table

| **Aspect**               | **Description**                                                   | **Example**                                              |
|--------------------------|-------------------------------------------------------------------|----------------------------------------------------------|
| **Bag of Words Assumption** | Treats word positions as irrelevant.                            | "The cat sleeps" = "Sleeps the cat."                     |
| **Conditional Independence** | Assumes features are independent given the class.              | $P(c\|x) \propto P(c) \prod P(x_i\|c)$.                    |
| **Precision**             | Measures accuracy of positive predictions.                      | Spam detection.                                          |
| **Recall**                | Measures completeness of positive predictions.                  | Disease detection.                                       |
| **Posting List**          | List of document IDs where a term occurs.                       | Term: "cat", Posting List: [7, 3, 10, 42].               |
| **Phrase Query**          | Searches for exact phrases in documents.                       | Query: `"cat sleeps"`.                                   |
| **Proximity Queries**     | Finds terms within a certain distance.                         | Query: `"cat sleeps" within 5 words.`                    |
| **TF-IDF**                | Scoring scheme based on term frequency and rarity.             | $TF-IDF(t) = TF(t) \times IDF(t)$.                      |
